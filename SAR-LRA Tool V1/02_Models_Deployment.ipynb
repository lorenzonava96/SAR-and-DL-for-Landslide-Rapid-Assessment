{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAR-LRA VV_VH Models Deployment\n",
    "\n",
    "This notebook deploys the two models on the composite SAR images acquired in 01_SAR-LRA_Sentinel-1_Image_Acquisition for ascending and descending orbits, VV_VH combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rasterio version: 1.2.10\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "print(\"Rasterio version:\", rasterio.__version__) # Version 1.2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "NumPy version: 1.21.5\n",
      "OpenCV version: 4.5.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "# from PIL import Image\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from utils import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)  # Version 2.10.0\n",
    "print(\"NumPy version:\", np.__version__)       # Version 1.21.5\n",
    "print(\"OpenCV version:\", cv2.__version__)     # Version 4.5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCENDING\n",
    "\n",
    "### 1. Defining useful variables\n",
    "Here we define some variables and paths that will be useful to call model weights, images, and saving the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = 'Sumatra' # name of the event or location\n",
    "\n",
    "orbit = 'DESCENDING'\n",
    "\n",
    "# directory of the SAR composite image\n",
    "image_path = f'deploy/VV_VH/60_12/SAR_{orbit}_.tif' \n",
    "\n",
    "# directory of the weights of the model\n",
    "weights = f'model_weights/VV_VH_60_nn_noSlope_DESCENDING_60_12_5_size_64_filters_64_batch_size_512_lr_0.001_dropout_0.7_fil1_3_fil2_3_fil3_3.hdf5'\n",
    "\n",
    "# size of the image\n",
    "size = 64\n",
    "\n",
    "# number of bands\n",
    "channels = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Model and Image\n",
    "Remember to define the model parameters as the one used in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model weights...\n",
      "[INFO] loading image...\n",
      "MODEL AND IMAGE ARE READY !\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "model = CNN_CBAM(filtersFirstLayer= 64, drop = 0.7, lr = 0.001, input_size = (size, size, channels), loss=focal_loss)\n",
    "print(\"[INFO] loading model weights...\")\n",
    "model.load_weights(weights)\n",
    "\n",
    "# import image\n",
    "print(\"[INFO] loading image...\")\n",
    "with rasterio.open(image_path) as ori:\n",
    "    tmp = np.moveaxis(ori.read(), 0, 2)\n",
    "orig = np.asarray(tmp)\n",
    "orig = orig[:,:,:(channels)]\n",
    "\n",
    "print('MODEL AND IMAGE ARE READY !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the Sliding Window algorithm\n",
    "Here, we execute the sliding window algorithm to extract 64x64 images from the SAR composite image downloaded in the preceding notebook, 01_SAR-LRA_Sentinel-1_Image_Acquisition, with a specified overlap. Subsequently, we store these images along with their corresponding coordinates relative to the original image in two separate lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] looping over pyramid/windows took 11.64422 seconds\n",
      "[INFO] You extracted  29584 patches\n",
      "ROIs ARE READY TO BE CLASSIFIED !\n"
     ]
    }
   ],
   "source": [
    "rois = [] # list for images\n",
    "locs = [] # list for coordinates\n",
    "\n",
    "ROI_SIZE = (size, size) # 64x64\n",
    "WIN_STEP = int(size/2)  # 32 to have 50% of overlap - modifiable\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for (x, y, roiOrig) in sliding_window(orig, WIN_STEP, ROI_SIZE):\n",
    "    w = int(ROI_SIZE[0])\n",
    "    h = int(ROI_SIZE[1])\n",
    "    roi = cv2.resize(roiOrig, ROI_SIZE)\n",
    "    roi = img_to_array(roi)\n",
    "    rois.append(roi)\n",
    "    locs.append((x, y, x + w, y + h))\n",
    "    end = time.time()\n",
    "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(end - start))\n",
    "\n",
    "# convert the ROIs to a NumPy array\n",
    "rois = np.array(rois)\n",
    "print('[INFO] You extracted ', len(rois), 'patches')\n",
    "\n",
    "print('ROIs ARE READY TO BE CLASSIFIED !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classify the extracted images\n",
    "Here, we classify all the images (ROIs) extracted by the sliding window algorithm, saving the predictions as probabilities ranging from 0 to 1, indicating their likelihood of belonging to the landslide class. Subsequently, we will define a probability threshold to determine the class to which they belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] classifying ROIs...\n",
      "58/58 [==============================] - 6s 40ms/step\n",
      "[INFO] classifying ROIs took 5.70280 seconds\n",
      "THE MODEL CLASSIFIED ALL THE ROIs !\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] classifying ROIs...\")\n",
    "start = time.time()\n",
    "pred_datagen = ImageDataGenerator()\n",
    "batch_size = 512\n",
    "pred_ds = pred_datagen.flow(rois, batch_size = batch_size, seed = 42, shuffle=False)\n",
    "ynew = model.predict(pred_ds) # predict\n",
    "end = time.time()\n",
    "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
    "    end - start))\n",
    "\n",
    "print('THE MODEL CLASSIFIED ALL THE ROIs !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Count the number of ROIs predicted as landslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "for i, prob in enumerate(ynew):\n",
    "    if prob > 0.6: # probability threshold\n",
    "        n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Append coordinates and probability value of the ROIs predicted as landslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "P = []\n",
    "for i, prob in enumerate(ynew):\n",
    "    if prob > 0.6: # probability threshold\n",
    "        box = locs[i]\n",
    "        L.append(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deploy Non-Maximum Suppression\n",
    "The non max suppression used is the one developed by Adrian Rosebrock and it is very well explained here:\n",
    "https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = np.array(L) # to array\n",
    "boxes = non_max_suppression_fast(boxes, overlapThresh=0.1) # select overlap threshold between bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Draw the final bounding boxes and save as TIFF file\n",
    "We delineate the ultimate bounding boxes around the detected landslides by the model, and we generate the final georeferenced raster, marking landslide boxes contours with 1 and non-landslide areas with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the original image\n",
    "clone = orig.copy() \n",
    "\n",
    "# create an empty image (with zeros)\n",
    "c = np.zeros((clone.shape[0], clone.shape[1]), dtype=np.uint8)\n",
    "\n",
    "# iterate through the boxes and draw them on the image\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "    # Draw rectangle (bounding box) on the image\n",
    "    cv2.rectangle(c, (startX, startY), (endX, endY), color=1, thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION SAVED !\n"
     ]
    }
   ],
   "source": [
    "pred_path = f'predictions/{place}_DESCENDING.tif' # directory and name of output TIFF file\n",
    "ori =  rasterio.open(image_path)\n",
    "c = np.squeeze(c)\n",
    "\n",
    "with rasterio.Env():\n",
    "    profile = ori.profile\n",
    "    profile.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1,\n",
    "        width= c.shape[-1], \n",
    "        height= c.shape[-2],\n",
    "        compress='lzw')\n",
    "    with rasterio.open(pred_path, 'w', **profile) as dst:\n",
    "        dst.write(c.astype(rasterio.float32), 1)\n",
    "        \n",
    "print('PREDICTION SAVED AS TIFF !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save the predictions as a Shapefile\n",
    "The predictions are saved in the folder: predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Open the georeferenced TIFF image\n",
    "with rasterio.open(pred_path) as src:\n",
    "    # Read the raster data as a numpy array\n",
    "    image_array = src.read(1)\n",
    "\n",
    "    # Get the transform (georeferencing information)\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "\n",
    "    # Generate shapes for areas where pixel values are equal to 1\n",
    "    shapes = list(shapes(image_array, transform=transform))\n",
    "\n",
    "# Filter shapes where pixel value is 1\n",
    "valid_shapes = [s for s, v in shapes if v == 1]\n",
    "\n",
    "# Convert valid shapes to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(geometry=[shape(s) for s in valid_shapes], crs=crs)\n",
    "shapefile_path = pred_path + \".shp\"\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "gdf.to_file(shapefile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASCENDING\n",
    "We will iterate through the methodology once more. The elements that will vary are the model, with the new one trained on Ascending data, and the composite SAR image, which will now be from the Ascending orbit.\n",
    "\n",
    "### 1. Defining useful variables\n",
    "Here we define some variables and paths that will be useful to call model weights, images, and saving the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = 'Sumatra' # name of the event or location\n",
    "\n",
    "orbit = 'ASCENDING'\n",
    "\n",
    "# directory of the SAR composite image\n",
    "image_path = f'deploy/VV_VH/60_12/SAR_{orbit}_.tif' \n",
    "\n",
    "# directory of the weights of the model\n",
    "weights = f'model_weights/VV_VH_60_nn_noSlope_ASCENDING_60_12_6_size_64_filters_32_batch_size_512_lr_0.001_dropout_0.7_fil1_3_fil2_3_fil3_3.hdf5'\n",
    "\n",
    "# size of the image\n",
    "size = 64\n",
    "\n",
    "# number of bands\n",
    "channels = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Model and Image\n",
    "Remember to define the model parameters as the one used in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model weights...\n",
      "[INFO] loading image...\n",
      "MODEL AND IMAGE ARE READY !\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "model = CNN_CBAM(filtersFirstLayer= 32, drop = 0.7, lr = 0.001, input_size = (size, size, channels), loss=focal_loss)\n",
    "print(\"[INFO] loading model weights...\")\n",
    "model.load_weights(weights)\n",
    "\n",
    "# import image\n",
    "print(\"[INFO] loading image...\")\n",
    "with rasterio.open(image_path) as ori:\n",
    "    tmp = np.moveaxis(ori.read(), 0, 2)\n",
    "orig = np.asarray(tmp)\n",
    "orig = orig[:,:,:(channels)]\n",
    "\n",
    "print('MODEL AND IMAGE ARE READY !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the Sliding Window algorithm\n",
    "Here, we execute the sliding window algorithm to extract 64x64 images from the SAR composite image downloaded in the preceding notebook, 01_SAR-LRA_Sentinel-1_Image_Acquisition, with a specified overlap. Subsequently, we store these images along with their corresponding coordinates relative to the original image in two separate lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] looping over pyramid/windows took 8.25361 seconds\n",
      "[INFO] You extracted  29584 patches\n",
      "ROIs ARE READY TO BE CLASSIFIED !\n"
     ]
    }
   ],
   "source": [
    "rois = [] # list for images\n",
    "locs = [] # list for coordinates\n",
    "\n",
    "ROI_SIZE = (size, size) # 64x64\n",
    "WIN_STEP = int(size/2)  # 32 to have 50% of overlap - modifiable\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for (x, y, roiOrig) in sliding_window(orig, WIN_STEP, ROI_SIZE):\n",
    "    w = int(ROI_SIZE[0])\n",
    "    h = int(ROI_SIZE[1])\n",
    "    roi = cv2.resize(roiOrig, ROI_SIZE)\n",
    "    roi = img_to_array(roi)\n",
    "    rois.append(roi)\n",
    "    locs.append((x, y, x + w, y + h))\n",
    "    end = time.time()\n",
    "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(end - start))\n",
    "\n",
    "# convert the ROIs to a NumPy array\n",
    "rois = np.array(rois)\n",
    "print('[INFO] You extracted ', len(rois), 'patches')\n",
    "\n",
    "print('ROIs ARE READY TO BE CLASSIFIED !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classify the extracted images\n",
    "Here, we classify all the images (ROIs) extracted by the sliding window algorithm, saving the predictions as probabilities ranging from 0 to 1, indicating their likelihood of belonging to the landslide class. Subsequently, we will define a probability threshold to determine the class to which they belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] classifying ROIs...\n",
      "58/58 [==============================] - 3s 34ms/step\n",
      "[INFO] classifying ROIs took 2.76405 seconds\n",
      "THE MODEL CLASSIFIED ALL THE ROIs !\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] classifying ROIs...\")\n",
    "start = time.time()\n",
    "pred_datagen = ImageDataGenerator()\n",
    "batch_size = 512\n",
    "pred_ds = pred_datagen.flow(rois, batch_size = batch_size, seed = 42, shuffle=False)\n",
    "ynew = model.predict(pred_ds) # predict\n",
    "end = time.time()\n",
    "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
    "    end - start))\n",
    "\n",
    "print('THE MODEL CLASSIFIED ALL THE ROIs !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Count the number of ROIs predicted as landslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "for i, prob in enumerate(ynew):\n",
    "    if prob > 0.6: # probability threshold\n",
    "        n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Append coordinates and probability value of the ROIs predicted as landslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "P = []\n",
    "for i, prob in enumerate(ynew):\n",
    "    if prob > 0.6: # probability threshold\n",
    "        box = locs[i]\n",
    "        L.append(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deploy Non-Maximum Suppression\n",
    "The non max suppression used is the one developed by Adrian Rosebrock and it is very well explained here:\n",
    "https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = np.array(L)\n",
    "boxes = non_max_suppression_fast(boxes, overlapThresh=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Draw the final bounding boxes and save as TIFF file\n",
    "We delineate the ultimate bounding boxes around the detected landslides by the model, and we generate the final georeferenced raster, marking landslide boxes contours with 1 and non-landslide areas with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty image (black image with zeros)\n",
    "c = np.zeros((clone.shape[0], clone.shape[1]), dtype=np.uint8)\n",
    "\n",
    "# Iterate through the boxes and draw them on the image\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "    # Draw rectangle (bounding box) on the image\n",
    "    cv2.rectangle(c, (startX, startY), (endX, endY), color=1, thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION SAVED AS TIFF !\n"
     ]
    }
   ],
   "source": [
    "pred_path = f'predictions/{place}_ASCENDING.tif' # directory and name of output TIFF file\n",
    "ori =  rasterio.open(image_path)\n",
    "c = np.squeeze(c)\n",
    "\n",
    "with rasterio.Env():\n",
    "    profile = ori.profile\n",
    "    profile.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1,\n",
    "        width= c.shape[-1], \n",
    "        height= c.shape[-2],\n",
    "        compress='lzw')\n",
    "    with rasterio.open(pred_path, 'w', **profile) as dst:\n",
    "        dst.write(c.astype(rasterio.float32), 1)\n",
    "        \n",
    "print('PREDICTION SAVED AS TIFF !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save the predictions as a Shapefile\n",
    "The predictions are saved in the folder: predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Open the georeferenced TIFF image\n",
    "with rasterio.open(pred_path) as src:\n",
    "    # Read the raster data as a numpy array\n",
    "    image_array = src.read(1)\n",
    "\n",
    "    # Get the transform (georeferencing information)\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "\n",
    "    # Generate shapes for areas where pixel values are equal to 1\n",
    "    shapes = list(shapes(image_array, transform=transform))\n",
    "\n",
    "# Filter shapes where pixel value is 1\n",
    "valid_shapes = [s for s, v in shapes if v == 1]\n",
    "\n",
    "# Convert valid shapes to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(geometry=[shape(s) for s in valid_shapes], crs=crs)\n",
    "shapefile_path = pred_path + \".shp\"\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "gdf.to_file(shapefile_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
