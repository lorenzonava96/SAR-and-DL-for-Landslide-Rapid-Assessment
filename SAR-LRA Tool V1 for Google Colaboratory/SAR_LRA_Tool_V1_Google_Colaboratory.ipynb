{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvSMPPl9qaV4"
      },
      "source": [
        "# SAR-LRA Tool for Google Colaboratory\n",
        "\n",
        "This notebook facilitates the acquisition of Sentinel-1 SAR composite imagery for the VV_VH combination, encompassing both ascending and descending orbits, which can then be utilized to deploy the models.\n",
        "\n",
        "Without modifications the notebook will predict in Taiwan.\n",
        
        "\n",
        "### IMPORTANT:\n",
        "Select a runtime with large RAM (such as TPU), otherwise the processing will brake."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install some libraries\n",
        "\n",
        "!pip install geedim\n",
        "!pip install leafmap==0.22.0\n",
        "!pip install geemap==0.24.1\n",
        "!pip install -U geemap\n",
        "!pip install earthengine-api"
      ],
      "metadata": {
        "id": "OR8ZUG0CEnJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DSQampXqaV-"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "import datetime\n",
        "import leafmap          # Version 0.22.0\n",
        "import geemap           # Version 0.24.1\n",
        "import ee               # Version 0.1.358\n",
        "from glob import glob\n",
        "import numpy as np      # Version 1.25.0\n",
        "import pandas as pd     # Version 2.0.3\n",
        "import os\n",
        "\n",
        "# Print versions\n",
        "print(\"leafmap:\", leafmap.__version__)\n",
        "print(\"geemap:\", geemap.__version__)\n",
        "print(\"Earth Engine API:\", ee.__version__)\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"pandas:\", pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "291_nVI3qaWB"
      },
      "source": [
        "## 2. Autenticate and initialize the Google Earth Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATYsQc4sqaWB"
      },
      "outputs": [],
      "source": [
        "m = geemap.Map()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwMPVr2EqaWC"
      },
      "source": [
        "## 3. Define the Area of Interest\n",
        "\n",
        "Designe a polygon that includes your area of interest (AOI). For this tutorial we pre defined the AOI for Taiwan."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the world countries dataset\n",
        "worldcountries = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n",
        "# Filter Taiwan\n",
        "filterCountry = ee.Filter.eq('country_co', 'TW')\n",
        "AoI = worldcountries.filter(filterCountry)\n",
        "\n",
        "# Create a Map instance\n",
        "Map = geemap.Map()\n",
        "\n",
        "# Add the country border to the map\n",
        "Map.addLayer(AoI, {}, 'Country Border')\n",
        "\n",
        "# Define Sentinel-2 post-event parameters\n",
        "start_date = '2024-04-27'\n",
        "end_date = '2024-05-01'\n",
        "cloud_percentage = 30\n",
        "\n",
        "# Load Sentinel-2 imagery\n",
        "sentinel_2 = ee.ImageCollection('COPERNICUS/S2') \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .filterBounds(AoI) \\\n",
        "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', cloud_percentage))\n",
        "\n",
        "# Print the number of images found\n",
        "print(\"Number of images:\", sentinel_2.size().getInfo())\n",
        "\n",
        "# Calculate median and clip to the AOI\n",
        "sentinel_2 = sentinel_2.median().clip(AoI)\n",
        "# Select bands for true color imagery\n",
        "sentinel_2 = sentinel_2.select(['B2', 'B3', 'B4'])\n",
        "# Define true color visualization parameters\n",
        "trueColor_palette = {\n",
        "  'bands': ['B4', 'B3', 'B2'],\n",
        "  'min': 0,\n",
        "  'max': 3000\n",
        "}\n",
        "# Add true color Sentinel-2 imagery to the map\n",
        "Map.addLayer(sentinel_2, trueColor_palette, \"Sentinel-2 True Color\")\n",
        "\n",
        "# Center the map on the dataset\n",
        "Map.centerObject(AoI, 5)\n",
        "\n",
        "# Display the map\n",
        "Map"
      ],
      "metadata": {
        "id": "3tH76DVOs6LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zabF7fbnqaWD"
      },
      "source": [
        "## 4. Define temporal buffers and temporal stacks\n",
        "The following dates are for the Sumatra earthquake on the 25th of February 2022. Change the dates according to the MLE you want to deploy the model for.\n",
        "\n",
        "Taiwan earthquake: 2/4/2024\n",
        "\n",
        "IMPORTANT: The landslide MUST be occurred in between the pre_end and post_start dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mhm0LHM4qaWD"
      },
      "outputs": [],
      "source": [
        "# Convert the drawn geometry to an Earth Engine Geometry object\n",
        "# geometry = ee.FeatureCollection(Map.draw_features) # for this tutorial we will use the box_coordinates defined in the following box.\n",
        "\n",
        "pre_stack_end = '2024-04-02'\n",
        "post_stack_start = '2024-04-02'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-4rXrIXqaWE"
      },
      "outputs": [],
      "source": [
        "### UNCOMMENT THIS TO DEFINE GEOMETRY FOR THE TAIWAN EVENT\n",
        "\n",
        "box_coordinates = [[\n",
        "    [121.28320081506229,23.673234207076405],\n",
        "    [121.83526380334354,23.673234207076405],\n",
        "    [121.83526380334354,24.460681113046533],\n",
        "    [121.28320081506229,24.460681113046533],\n",
        "    [121.28320081506229,23.673234207076405]\n",
        "]]\n",
        "\n",
        "geometry = ee.Geometry.Polygon(box_coordinates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFaEoJ6SqaWE"
      },
      "source": [
        "## 5. Process and Download Sentinel-1 SAR composite images\n",
        "In certain areas where VH polarization data is unavailable, the notebook may encounter errors as it is designed to download both VV and VH data. The same applies to the ascending and descending orbits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "RPDlP_gUqaWF"
      },
      "outputs": [],
      "source": [
        "print('SENTINEL 1 SAR IMAGE PROCESSING AND ACQUISITION !')\n",
        "print('_____________________________________________________________________________________')\n",
        "\n",
        "orbits = ['DESCENDING', 'ASCENDING'] # Orbits to download\n",
        "pre_days = 60 # pre event stack dimensions\n",
        "post_days = 12 # pre event stack dimensions\n",
        "\n",
        "# Define date ranges\n",
        "pre_end = datetime.datetime.strptime(pre_stack_end, \"%Y-%m-%d\")\n",
        "pre_start = pre_end - datetime.timedelta(days=pre_days)\n",
        "print('Pre stack start:', pre_start)\n",
        "print('Pre stack end:',pre_end)\n",
        "pre_end = ee.Date(pre_end)\n",
        "pre_start = ee.Date(pre_start)\n",
        "\n",
        "post_start = datetime.datetime.strptime(post_stack_start, \"%Y-%m-%d\")\n",
        "post_end = post_start + datetime.timedelta(days=post_days)\n",
        "print('Post stack start:',post_start)\n",
        "print('Post stack end:',post_end)\n",
        "post_start = ee.Date(post_start)\n",
        "post_end = ee.Date(post_end)\n",
        "\n",
        "for orbit in orbits:\n",
        "    print('Orbit: ', orbit)\n",
        "    project_path = ''\n",
        "    inputs_path = os.path.join(*[project_path, f'deploy/VV_VH/60_{post_days}'])\n",
        "    outputs_path = os.path.join(*[project_path, 'outputs'])\n",
        "    print('project_path: ', project_path); print('training_path: ', inputs_path); print('outputs_path: ', outputs_path)\n",
        "\n",
        "    print('_____________________________________________________________________________________')\n",
        "\n",
        "    # Make Image Collections\n",
        "    pre_data = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
        "        .filterBounds(geometry) \\\n",
        "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
        "        .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
        "        .filter(ee.Filter.eq('orbitProperties_pass', orbit)) \\\n",
        "        .filterDate(pre_start, pre_end)\n",
        "\n",
        "    pre_count = pre_data.size().getInfo()\n",
        "    print('Pre image count:', pre_count)\n",
        "\n",
        "    # Get a list of images in the collection\n",
        "    pre_list = pre_data.toList(pre_count)\n",
        "\n",
        "    # Iterate through each image in the collection\n",
        "    for i in range(pre_count):\n",
        "        image = ee.Image(pre_list.get(i))\n",
        "        image_id = image.id().getInfo()\n",
        "        date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
        "        print('Image ID:', image_id, ' Date:', date)\n",
        "\n",
        "    post_data = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
        "        .filterBounds(geometry) \\\n",
        "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
        "        .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
        "        .filter(ee.Filter.eq('orbitProperties_pass', orbit)) \\\n",
        "        .filterDate(post_start, post_end)\n",
        "\n",
        "    post_count = post_data.size().getInfo()\n",
        "    print('Post image count:', post_count)\n",
        "\n",
        "    # Get a list of images in the collection\n",
        "    post_list = post_data.toList(post_count)\n",
        "\n",
        "    # Iterate through each image in the collection\n",
        "    for i in range(post_count):\n",
        "        image = ee.Image(post_list.get(i))\n",
        "        image_id = image.id().getInfo()\n",
        "        date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
        "        print('Image ID:', image_id, ' Date:', date)\n",
        "\n",
        "    ### VV ###\n",
        "    pre_corrected_masked_VV = pre_data.select('VV') # Select VV polarization\n",
        "    pre_median_VV = pre_corrected_masked_VV.reduce(ee.Reducer.median())  # Calculate median\n",
        "    pre_median_VV = pre_median_VV.select(0).rename('preVV')  # Rename bands\n",
        "\n",
        "\n",
        "    post_corrected_masked_VV = post_data.select('VV')  # Select VV polarization\n",
        "    post_median_VV = post_corrected_masked_VV.reduce(ee.Reducer.median())  # Calculate median\n",
        "    post_median_VV = post_median_VV.select(0).rename('postVV')  # Rename bands\n",
        "\n",
        "    diff_VV = post_median_VV.subtract(pre_median_VV).rename('diffVV') # Change detection (post event - pre event)\n",
        "\n",
        "     ### VH ###\n",
        "    pre_corrected_masked_VH = pre_data.select('VH')   # Select VV polarization\n",
        "    pre_median_VH = pre_corrected_masked_VH.reduce(ee.Reducer.median())  # Calculate median\n",
        "    pre_median_VH = pre_median_VH.select(0).rename('preVH')  # Rename bands\n",
        "\n",
        "\n",
        "    post_corrected_masked_VH = post_data.select('VH')  # Select VV polarization\n",
        "    post_median_VH = post_corrected_masked_VH.reduce(ee.Reducer.median())  # Calculate median\n",
        "    post_median_VH = post_median_VH.select(0).rename('postVH')  # Rename bands\n",
        "\n",
        "    diff_VH = post_median_VH.subtract(pre_median_VH).rename('diffVH') # Change detection (post event - pre event)\n",
        "\n",
        "    DS = post_median_VV.addBands(post_median_VH).addBands(diff_VV).addBands(diff_VH) # Create composite SAR image\n",
        "    DS = DS.clip(geometry) # Clip composite SAR image to Area of Interest\n",
        "\n",
        "    ### GEE does not allow big downloads - therefore we dowload grid by grid, and re-merge afterwards.\n",
        "\n",
        "    # create fishnet (sample grid)\n",
        "    fishnet = geemap.fishnet(geometry, h_interval=0.5, v_interval=0.5, delta=1)\n",
        "\n",
        "    # download composite tiles\n",
        "    geemap.download_ee_image_tiles(DS, fishnet, inputs_path+'/'+'/VV_VH_'+orbit+'/', prefix=\"VV_VH_\"+orbit+'_'+'_', scale=10, crs=ee.Projection('EPSG:4326'))\n",
        "\n",
        "    # merge tiles and save\n",
        "    leafmap.merge_rasters(inputs_path+'/'+'/VV_VH_'+orbit, output=inputs_path+'/'+'/SAR_'+orbit+'_'+'.tif', input_pattern='*.tif')\n",
        "\n",
        "    # delete useless rasters inside folders\n",
        "    s2s = glob(inputs_path+'/'+'/VV_VH_'+orbit+'/*.tif')\n",
        "\n",
        "    for s2_file in s2s:\n",
        "        os.remove(s2_file)\n",
        "    os.rmdir(inputs_path+'/'+'/VV_VH_'+orbit)\n",
        "\n",
        "print('DONE !!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAR-LRA VV_VH Models Deployment\n",
        "The following part of the notebook deploys the two models on the composite SAR images previously acquired for ascending and descending orbits, VV_VH combination."
      ],
      "metadata": {
        "id": "UGVq4ofrvR-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install tensorflow opencv-python-headless\n",
        "!pip install requests"
      ],
      "metadata": {
        "id": "NKLlli30KpVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "# from PIL import Image\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "print(\"Rasterio version:\", rasterio.__version__) # Version 1.2.10\n",
        "print(\"TensorFlow version:\", tf.__version__)  # Version 2.10.0\n",
        "print(\"NumPy version:\", np.__version__)       # Version 1.21.5\n",
        "print(\"OpenCV version:\", cv2.__version__)     # Version 4.5.5"
      ],
      "metadata": {
        "id": "u6x9n3-_vWip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define some useful functions\n",
        "\n",
        "def CNN(lr, loss, filtersFirstLayer, drop, input_size=(64, 64, 4)):\n",
        "    inputs = Input(shape=input_size)\n",
        "    conv1 = Conv2D(filtersFirstLayer, 3, padding='same', activation='relu')(inputs)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D()(conv1)\n",
        "\n",
        "    conv2 = Conv2D(filtersFirstLayer, 3, padding='same', activation='relu')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D()(conv2)\n",
        "\n",
        "    conv3 = Conv2D(filtersFirstLayer, 3, padding='same', activation='relu')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "\n",
        "    target_shape = (conv3.shape[1], conv3.shape[2])\n",
        "\n",
        "    resized_tensor_3 = tf.image.resize(conv3, target_shape)\n",
        "    resized_tensor_2 = tf.image.resize(conv2, target_shape)\n",
        "    resized_tensor_1 = tf.image.resize(conv1, target_shape)\n",
        "\n",
        "    concatenated_tensor = tf.concat([resized_tensor_3, resized_tensor_3, resized_tensor_3], axis=-1)\n",
        "\n",
        "    pool3 = MaxPooling2D()(concatenated_tensor)\n",
        "\n",
        "    drop1 = Dropout(drop)(pool3)\n",
        "    flat = Flatten()(drop1)\n",
        "    en = Dense(filtersFirstLayer * 8, activation='relu')(flat)\n",
        "    out = Dense(1, activation='sigmoid')(en)\n",
        "    model = Model(inputs, out)\n",
        "\n",
        "    model.compile(loss=loss, optimizer=Adam(learning_rate=lr), metrics='accuracy')\n",
        "    return model\n",
        "\n",
        "def focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
        "    # Compute binary cross-entropy\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=True)\n",
        "\n",
        "    # Compute the predicted probabilities for the true class\n",
        "    p_t = tf.math.exp(-bce)\n",
        "\n",
        "    # Compute the focal loss\n",
        "    focal_loss = alpha * (1 - p_t) ** gamma * bce\n",
        "\n",
        "    return focal_loss\n",
        "\n",
        "def non_max_suppression_fast(boxes, overlapThresh):\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "\n",
        "    pick = []\n",
        "    x1 = boxes[:,0]\n",
        "    y1 = boxes[:,1]\n",
        "    x2 = boxes[:,2]\n",
        "    y2 = boxes[:,3]\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    idxs = np.argsort(y2)\n",
        "\n",
        "    while len(idxs) > 0:\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
        "\n",
        "    return boxes[pick].astype(\"int\")\n",
        "\n",
        "def sliding_window(image, step, ws):\n",
        "    for y in range(0, image.shape[0] - ws[1], step):\n",
        "        for x in range(0, image.shape[1] - ws[0], step):\n",
        "            yield (x, y, image[y:y + ws[1], x:x + ws[0]])"
      ],
      "metadata": {
        "id": "_4nm5ae4_gUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DESCENDING orbit\n",
        "\n",
        "### 1. Defining useful variables\n",
        "Here we define some variables and paths that will be useful to call model weights, images, and saving the outputs."
      ],
      "metadata": {
        "id": "BCWSyCJ8xHpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "place = 'Taiwan' # name of the event or location\n",
        "\n",
        "orbit = 'DESCENDING'\n",
        "\n",
        "# directory of the SAR composite image\n",
        "image_path = f'deploy/VV_VH/60_12/SAR_{orbit}_.tif'\n",
        "\n",
        "# ulr of the weights of the model\n",
        "github_url = \"https://github.com/lorenzonava96/SAR-and-DL-for-Landslide-Rapid-Assessment/raw/main/SAR-LRA%20Tool%20V1/model_weights/VV_VH_60_nn_noSlope_DESCENDING_60_12_5_size_64_filters_64_batch_size_512_lr_0.001_dropout_0.7_fil1_3_fil2_3_fil3_3.hdf5\"\n",
        "\n",
        "# size of the image\n",
        "size = 64\n",
        "\n",
        "# number of bands\n",
        "channels = 4"
      ],
      "metadata": {
        "id": "SjoAtGAhxPT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Import Model and Image\n",
        "Remember to define the model parameters as the one used in the training. We call the model weights from the github directory.\n"
      ],
      "metadata": {
        "id": "V3ky068wxS3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model parameters and import model\n",
        "model = CNN(filtersFirstLayer=64, drop=0.7, lr=0.001, input_size=(size, size, channels), loss=focal_loss)\n",
        "print(\"[INFO] loading model weights...\")\n",
        "\n",
        "# Make a GET request to fetch the contents of the HDF5 file\n",
        "response = requests.get(github_url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Write the contents of the HDF5 file to a local file\n",
        "    with open(\"model_weights_desce.hdf5\", \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "    print(\"HDF5 file downloaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to fetch the HDF5 file from GitHub\")\n",
        "\n",
        "# Load the weights into the model\n",
        "model.load_weights(\"model_weights_desce.hdf5\")\n",
        "\n",
        "# Load and preprocess the image\n",
        "print(\"[INFO] loading image...\")\n",
        "with rasterio.open(image_path) as ori:\n",
        "    tmp = np.moveaxis(ori.read(), 0, 2)\n",
        "orig = np.asarray(tmp)\n",
        "orig = orig[:, :, :(channels)]\n",
        "\n",
        "print('MODEL AND IMAGE ARE READY !')"
      ],
      "metadata": {
        "id": "bI9w9Xafz3rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Run the Sliding Window algorithm\n",
        "Here, we execute the sliding window algorithm to extract 64x64 images from the SAR composite image downloaded in the preceding notebook, 01_SAR-LRA_Sentinel-1_Image_Acquisition, with a specified overlap. Subsequently, we store these images along with their corresponding coordinates relative to the original image in two separate lists."
      ],
      "metadata": {
        "id": "QtbJPe2p0cWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rois = [] # list for images\n",
        "locs = [] # list for coordinates\n",
        "\n",
        "ROI_SIZE = (size, size) # 64x64\n",
        "WIN_STEP = int(size/2)  # 32 to have 50% of overlap - modifiable\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for (x, y, roiOrig) in sliding_window(orig, WIN_STEP, ROI_SIZE):\n",
        "    w = int(ROI_SIZE[0])\n",
        "    h = int(ROI_SIZE[1])\n",
        "    roi = cv2.resize(roiOrig, ROI_SIZE)\n",
        "    roi = img_to_array(roi)\n",
        "    rois.append(roi)\n",
        "    locs.append((x, y, x + w, y + h))\n",
        "    end = time.time()\n",
        "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(end - start))\n",
        "\n",
        "# convert the ROIs to a NumPy array\n",
        "rois = np.array(rois)\n",
        "print('[INFO] You extracted ', len(rois), 'patches')\n",
        "\n",
        "print('ROIs ARE READY TO BE CLASSIFIED !')"
      ],
      "metadata": {
        "id": "E_Umgx030efv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Classify the extracted images\n",
        "Here, we classify all the images (ROIs) extracted by the sliding window algorithm, saving the predictions as probabilities ranging from 0 to 1, indicating their likelihood of belonging to the landslide class. Subsequently, we will define a probability threshold to determine the class to which they belong."
      ],
      "metadata": {
        "id": "Eu38qPIq0jwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] classifying ROIs...\")\n",
        "start = time.time()\n",
        "pred_datagen = ImageDataGenerator()\n",
        "batch_size = 512\n",
        "pred_ds = pred_datagen.flow(rois, batch_size = batch_size, seed = 42, shuffle=False)\n",
        "ynew = model.predict(pred_ds) # predict\n",
        "end = time.time()\n",
        "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
        "    end - start))\n",
        "\n",
        "print('THE MODEL CLASSIFIED ALL THE ROIs !')"
      ],
      "metadata": {
        "id": "LRUpP_-40lA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Count the number of ROIs predicted as landslide\n"
      ],
      "metadata": {
        "id": "zH85ouoU1V3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1\n",
        "for i, prob in enumerate(ynew):\n",
        "    if prob > 0.6: # probability threshold\n",
        "        n += 1\n",
        "print(n)"
      ],
      "metadata": {
        "id": "GtLK75xE1ZXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Append coordinates and probability value of the ROIs predicted as landslide"
      ],
      "metadata": {
        "id": "TuNaviXC1bMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = []\n",
        "P = []\n",
        "for i, prob in enumerate(ynew):\n",
        "    if prob > 0.6: # probability threshold\n",
        "        box = locs[i]\n",
        "        L.append(box)"
      ],
      "metadata": {
        "id": "nTtTDMvT1do6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Deploy Non-Maximum Suppression\n",
        "The non max suppression used is the one developed by Adrian Rosebrock and it is very well explained here: https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/"
      ],
      "metadata": {
        "id": "cSZU33sT1f0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boxes = np.array(L) # to array\n",
        "boxes = non_max_suppression_fast(boxes, overlapThresh=0.1) # select overlap threshold between bounding boxes"
      ],
      "metadata": {
        "id": "tW7TAWcP1iCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Draw the final bounding boxes and save as TIFF file\n",
        "We delineate the ultimate bounding boxes around the detected landslides by the model, and we generate the final georeferenced raster, marking landslide boxes contours with 1 and non-landslide areas with 0."
      ],
      "metadata": {
        "id": "A5-bOghJ1nCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the original image\n",
        "clone = orig.copy()\n",
        "\n",
        "# create an empty image (with zeros)\n",
        "c = np.zeros((clone.shape[0], clone.shape[1]), dtype=np.uint8)\n",
        "\n",
        "# iterate through the boxes and draw them on the image\n",
        "for (startX, startY, endX, endY) in boxes:\n",
        "    # Draw rectangle (bounding box) on the image\n",
        "    cv2.rectangle(c, (startX, startY), (endX, endY), color=1, thickness=1)"
      ],
      "metadata": {
        "id": "y9vVwneq1qEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "# Print the current directory\n",
        "print(\"Current directory:\", current_directory)"
      ],
      "metadata": {
        "id": "JQ_vt8y221xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_folder = \"predictions\"\n",
        "\n",
        "# Create the predictions folder if it doesn't exist\n",
        "if not os.path.exists(predictions_folder):\n",
        "    os.makedirs(predictions_folder)\n",
        "\n",
        "pred_path = f'predictions/{place}_DESCENDING.tif' # directory and name of output TIFF file\n",
        "ori =  rasterio.open(image_path)\n",
        "c = np.squeeze(c)\n",
        "\n",
        "with rasterio.Env():\n",
        "    profile = ori.profile\n",
        "    profile.update(\n",
        "        dtype=rasterio.float32,\n",
        "        count=1,\n",
        "        width= c.shape[-1],\n",
        "        height= c.shape[-2],\n",
        "        compress='lzw')\n",
        "    with rasterio.open(pred_path, 'w', **profile) as dst:\n",
        "        dst.write(c.astype(rasterio.float32), 1)\n",
        "\n",
        "print('PREDICTION SAVED AS TIFF !')"
      ],
      "metadata": {
        "id": "UtQGN3np1rrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Save the predictions as a Shapefile\n",
        "The predictions are saved in the folder: predictions.\n"
      ],
      "metadata": {
        "id": "OQoxRDH02nJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "MWC8flrMEkHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import shape\n",
        "\n",
        "# Open the georeferenced TIFF image\n",
        "with rasterio.open(pred_path) as src:\n",
        "    # Read the raster data as a numpy array\n",
        "    image_array = src.read(1)\n",
        "\n",
        "    # Get the transform (georeferencing information)\n",
        "    transform = src.transform\n",
        "    crs = src.crs\n",
        "\n",
        "    # Generate shapes for areas where pixel values are equal to 1\n",
        "    shapes = list(shapes(image_array, transform=transform))\n",
        "\n",
        "# Filter shapes where pixel value is 1\n",
        "valid_shapes = [s for s, v in shapes if v == 1]\n",
        "\n",
        "# Convert valid shapes to GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(geometry=[shape(s) for s in valid_shapes], crs=crs)\n",
        "shapefile_path = pred_path + \".shp\"\n",
        "# Save the GeoDataFrame as a shapefile\n",
        "gdf.to_file(shapefile_path)"
      ],
      "metadata": {
        "id": "JxBSFzBz2ozS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ASCENDING\n",
        "We will iterate through the methodology once more. The elements that will vary are the model, with the new one trained on Ascending data, and the composite SAR image, which will now be from the Ascending orbit.\n",
        "\n",
        "### 1. Defining useful variables\n",
        "Here we define some variables and paths that will be useful to call model weights, images, and saving the outputs."
      ],
      "metadata": {
        "id": "kIfEetJCFzOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "place = 'Taiwan' # name of the event or location\n",
        "\n",
        "orbit = 'ASCENDING'\n",
        "\n",
        "# directory of the SAR composite image\n",
        "image_path = f'deploy/VV_VH/60_12/SAR_{orbit}_.tif'\n",
        "\n",
        "# url of the weights of the model\n",
        "github_url = \"https://github.com/lorenzonava96/SAR-and-DL-for-Landslide-Rapid-Assessment/raw/main/SAR-LRA%20Tool%20V1/model_weights/VV_VH_60_nn_noSlope_ASCENDING_60_12_6_size_64_filters_32_batch_size_512_lr_0.001_dropout_0.7_fil1_3_fil2_3_fil3_3.hdf5\"\n",
        "\n",
        "# size of the image\n",
        "size = 64\n",
        "\n",
        "# number of bands\n",
        "channels = 4"
      ],
      "metadata": {
        "id": "nMr_wbi3Frxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Import Model and Image\n",
        "Remember to define the model parameters as the one used in the training."
      ],
      "metadata": {
        "id": "UVFLWkBpF2cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model parameters and import model\n",
        "model = CNN(filtersFirstLayer=32, drop=0.7, lr=0.001, input_size=(size, size, channels), loss=focal_loss)\n",
        "print(\"[INFO] loading model weights...\")\n",
        "\n",
        "# Make a GET request to fetch the contents of the HDF5 file\n",
        "response = requests.get(github_url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Write the contents of the HDF5 file to a local file\n",
        "    with open(\"model_weights_asce.hdf5\", \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "    print(\"HDF5 file downloaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to fetch the HDF5 file from GitHub\")\n",
        "\n",
        "# Load the weights into the model\n",
        "model.load_weights(\"model_weights_asce.hdf5\")\n",
        "\n",
        "# Load and preprocess the image\n",
        "print(\"[INFO] loading image...\")\n",
        "with rasterio.open(image_path) as ori:\n",
        "    tmp = np.moveaxis(ori.read(), 0, 2)\n",
        "orig = np.asarray(tmp)\n",
        "orig = orig[:, :, :(channels)]\n",
        "\n",
        "print('MODEL AND IMAGE ARE READY !')"
      ],
      "metadata": {
        "id": "ZDNeZm3fFr0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Run the Sliding Window algorithm\n",
        "Here, we execute the sliding window algorithm to extract 64x64 images from the SAR composite image downloaded in the preceding notebook, 01_SAR-LRA_Sentinel-1_Image_Acquisition, with a specified overlap. Subsequently, we store these images along with their corresponding coordinates relative to the original image in two separate lists."
      ],
      "metadata": {
        "id": "fvf797iaF9YG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rois = [] # list for images\n",
        "locs = [] # list for coordinates\n",
        "\n",
        "ROI_SIZE = (size, size) # 64x64\n",
        "WIN_STEP = int(size/2)  # 32 to have 50% of overlap - modifiable\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for (x, y, roiOrig) in sliding_window(orig, WIN_STEP, ROI_SIZE):\n",
        "    w = int(ROI_SIZE[0])\n",
        "    h = int(ROI_SIZE[1])\n",
        "    roi = cv2.resize(roiOrig, ROI_SIZE)\n",
        "    roi = img_to_array(roi)\n",
        "    rois.append(roi)\n",
        "    locs.append((x, y, x + w, y + h))\n",
        "    end = time.time()\n",
        "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(end - start))\n",
        "\n",
        "# convert the ROIs to a NumPy array\n",
        "rois = np.array(rois)\n",
        "print('[INFO] You extracted ', len(rois), 'patches')\n",
        "\n",
        "print('ROIs ARE READY TO BE CLASSIFIED !')"
      ],
      "metadata": {
        "id": "OJbLs4s_Fr2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Classify the extracted images\n",
        "Here, we classify all the images (ROIs) extracted by the sliding window algorithm, saving the predictions as probabilities ranging from 0 to 1, indicating their likelihood of belonging to the landslide class. Subsequently, we will define a probability threshold to determine the class to which they belong."
      ],
      "metadata": {
        "id": "mlRNgyuyF_zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] classifying ROIs...\")\n",
        "start = time.time()\n",
        "pred_datagen = ImageDataGenerator()\n",
        "batch_size = 512\n",
        "pred_ds = pred_datagen.flow(rois, batch_size = batch_size, seed = 42, shuffle=False)\n",
        "ynew = model.predict(pred_ds) # predict\n",
        "end = time.time()\n",
        "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
        "    end - start))\n",
        "\n",
        "print('THE MODEL CLASSIFIED ALL THE ROIs !')"
      ],
      "metadata": {
        "id": "ghd1CNMbFr4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Count the number of ROIs predicted as landslide"
      ],
      "metadata": {
        "id": "aeSKhFoMGEfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1\n",
        "for i, prob in enumerate(ynew):\n",
        "    if prob > 0.6: # probability threshold\n",
        "        n += 1\n",
        "print(n)"
      ],
      "metadata": {
        "id": "ub3B1WpFGECS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Append coordinates and probability value of the ROIs predicted as landslide"
      ],
      "metadata": {
        "id": "1Wr9rubiGJgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = []\n",
        "P = []\n",
        "for i, prob in enumerate(ynew):\n",
        "    if prob > 0.6: # probability threshold\n",
        "        box = locs[i]\n",
        "        L.append(box)"
      ],
      "metadata": {
        "id": "7G9EioYIGEE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Deploy Non-Maximum Suppression\n",
        "The non max suppression used is the one developed by Adrian Rosebrock and it is very well explained here:\n",
        "https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/"
      ],
      "metadata": {
        "id": "L-k5noZNGOCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boxes = np.array(L)\n",
        "boxes = non_max_suppression_fast(boxes, overlapThresh=0.1)"
      ],
      "metadata": {
        "id": "80BtUgl7GEIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Draw the final bounding boxes and save as TIFF file\n",
        "We delineate the ultimate bounding boxes around the detected landslides by the model, and we generate the final georeferenced raster, marking landslide boxes contours with 1 and non-landslide areas with 0."
      ],
      "metadata": {
        "id": "wi3ZZI-MG_d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the original image\n",
        "clone = orig.copy()\n",
        "\n",
        "# Create an empty image (black image with zeros)\n",
        "c = np.zeros((clone.shape[0], clone.shape[1]), dtype=np.uint8)\n",
        "\n",
        "# Iterate through the boxes and draw them on the image\n",
        "for (startX, startY, endX, endY) in boxes:\n",
        "    # Draw rectangle (bounding box) on the image\n",
        "    cv2.rectangle(c, (startX, startY), (endX, endY), color=1, thickness=1)"
      ],
      "metadata": {
        "id": "ITroBN1HFr6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_path = f'predictions/{place}_ASCENDING.tif' # directory and name of output TIFF file\n",
        "ori =  rasterio.open(image_path)\n",
        "c = np.squeeze(c)\n",
        "\n",
        "with rasterio.Env():\n",
        "    profile = ori.profile\n",
        "    profile.update(\n",
        "        dtype=rasterio.float32,\n",
        "        count=1,\n",
        "        width= c.shape[-1],\n",
        "        height= c.shape[-2],\n",
        "        compress='lzw')\n",
        "    with rasterio.open(pred_path, 'w', **profile) as dst:\n",
        "        dst.write(c.astype(rasterio.float32), 1)\n",
        "\n",
        "print('PREDICTION SAVED AS TIFF !')"
      ],
      "metadata": {
        "id": "DZ24AWioHEQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Save the predictions as a Shapefile\n",
        "The predictions are saved in the folder: predictions."
      ],
      "metadata": {
        "id": "GiM1Oxe3HIN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import shape\n",
        "\n",
        "# Open the georeferenced TIFF image\n",
        "with rasterio.open(pred_path) as src:\n",
        "    # Read the raster data as a numpy array\n",
        "    image_array = src.read(1)\n",
        "\n",
        "    # Get the transform (georeferencing information)\n",
        "    transform = src.transform\n",
        "    crs = src.crs\n",
        "\n",
        "    # Generate shapes for areas where pixel values are equal to 1\n",
        "    shapes = list(shapes(image_array, transform=transform))\n",
        "\n",
        "# Filter shapes where pixel value is 1\n",
        "valid_shapes = [s for s, v in shapes if v == 1]\n",
        "\n",
        "# Convert valid shapes to GeoDataFrame\n",
        "gdf2 = gpd.GeoDataFrame(geometry=[shape(s) for s in valid_shapes], crs=crs)\n",
        "shapefile_path = pred_path + \".shp\"\n",
        "# Save the GeoDataFrame as a shapefile\n",
        "gdf2.to_file(shapefile_path)"
      ],
      "metadata": {
        "id": "oLu2UHXsHEaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Display the results"
      ],
      "metadata": {
        "id": "RO83Ka5l_NRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Close any previously opened map\n",
        "Map.close()\n",
        "\n",
        "# Create a new map instance\n",
        "Map = geemap.Map()\n",
        "\n",
        "# Define the time period and cloud percentage for Sentinel-2 imagery\n",
        "start_date = '2024-04-27'\n",
        "end_date = '2024-05-01'\n",
        "cloud_percentage = 30\n",
        "\n",
        "# Load Sentinel-2 imagery\n",
        "sentinel_2 = ee.ImageCollection('COPERNICUS/S2') \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .filterBounds(geometry) \\\n",
        "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', cloud_percentage))\n",
        "\n",
        "print(\"Number of images:\", sentinel_2.size().getInfo())\n",
        "\n",
        "# Calculate median and clip to the geometry\n",
        "sentinel_2 = sentinel_2.median().clip(geometry)\n",
        "# Select bands for true color imagery\n",
        "sentinel_2 = sentinel_2.select(['B2', 'B3', 'B4'])\n",
        "# Define true color visualization parameters\n",
        "trueColor_palette = {\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'min': 0,\n",
        "    'max': 3000  # Adjust this value based on the radiometric properties of your image\n",
        "}\n",
        "\n",
        "# Add Sentinel-2 true color imagery to the map\n",
        "Map.addLayer(sentinel_2, trueColor_palette, \"Sentinel-2 RGB\")\n",
        "\n",
        "# Add other layers like DS, if available\n",
        "Map.addLayer(DS, {'bands': ['postVV'], 'min': [-28], 'max': [4], 'gamma': 0.65}, 'postVV', False)\n",
        "Map.addLayer(DS, {'bands': ['postVH'], 'min': [-28], 'max': [4], 'gamma': 0.65}, 'postVH', False)\n",
        "Map.addLayer(DS, {'bands': ['diffVV'], 'min': [-28], 'max': [4], 'gamma': 0.65}, 'diffVV', False)\n",
        "Map.addLayer(DS, {'bands': ['diffVH'], 'min': [-28], 'max': [4], 'gamma': 0.65}, 'diffVH', False)\n",
        "\n",
        "# Convert GeoDataFrames to GeoJSON for visualization\n",
        "geojson = leafmap.gdf_to_geojson(gdf, epsg=\"4326\")\n",
        "geojson2 = leafmap.gdf_to_geojson(gdf2, epsg=\"4326\")\n",
        "\n",
        "# Define styles for GeoJSON layers\n",
        "style1 = {\n",
        "    \"stroke\": True,\n",
        "    \"color\": \"blue\",\n",
        "    \"weight\": 2,\n",
        "    \"opacity\": 1,\n",
        "    \"fill\": True,\n",
        "    \"fillColor\": \"blue\",\n",
        "    \"fillOpacity\": 1,\n",
        "}\n",
        "style2 = {\n",
        "    \"stroke\": True,\n",
        "    \"color\": \"red\",\n",
        "    \"weight\": 2,\n",
        "    \"opacity\": 1,\n",
        "    \"fill\": True,\n",
        "    \"fillColor\": \"red\",\n",
        "    \"fillOpacity\": 1,\n",
        "}\n",
        "hover_style = {\"fillOpacity\": 1}\n",
        "\n",
        "# Add GeoJSON layers to the map\n",
        "Map.add_geojson(geojson, layer_name=\"DESCENDING predictions\", style=style1, hover_style=hover_style)\n",
        "Map.add_geojson(geojson2, layer_name=\"ASCENDING predictions\", style=style2, hover_style=hover_style)\n",
        "\n",
        "# Center the map on the geometry\n",
        "Map.centerObject(geometry)\n",
        "\n",
        "# Display the map\n",
        "Map\n"
      ],
      "metadata": {
        "id": "dneFsNzz3UYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9oFMHrI0PfDR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
